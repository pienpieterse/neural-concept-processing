{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cecf05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "\n",
    "from nilearn.input_data import NiftiMasker\n",
    "from nilearn.image import resample_to_img, math_img\n",
    "\n",
    "from scipy.stats import spearmanr, rankdata\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import os\n",
    "import pickle\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5eb50aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_start_indices = [0, 267, 492, 812, 1137, 1373]\n",
    "\n",
    "def residualize(X, confounds):\n",
    "    \"\"\"Vectorized residualization of fMRI data against confounds.\"\"\"\n",
    "    # Add intercept\n",
    "    confounds_aug = np.hstack([confounds, np.ones((confounds.shape[0], 1))])\n",
    "    betas, _, _, _ = np.linalg.lstsq(confounds_aug, X, rcond=None)\n",
    "    predicted = confounds_aug @ betas\n",
    "    residuals = X - predicted\n",
    "    return residuals\n",
    "\n",
    "def cross_validated_residualize(fmri_list, confound_list):\n",
    "    \"\"\"\n",
    "    Residualizes each run using confound model trained on other runs.\n",
    "    Returns a new list of residualized runs.\n",
    "    \"\"\"\n",
    "    residualized_runs = []\n",
    "    for i in range(len(fmri_list)):\n",
    "        # Prepare training confounds and fMRI\n",
    "        train_confounds = np.vstack([confound_list[j] for j in range(len(fmri_list)) if j != i])\n",
    "        train_fmri = np.vstack([fmri_list[j] for j in range(len(fmri_list)) if j != i])\n",
    "\n",
    "        # Fit model\n",
    "        confounds_aug = np.hstack([train_confounds, np.ones((train_confounds.shape[0], 1))])\n",
    "        betas, _, _, _ = np.linalg.lstsq(confounds_aug, train_fmri, rcond=None)\n",
    "\n",
    "        # Apply to test confounds\n",
    "        test_confounds = confound_list[i]\n",
    "        test_confounds_aug = np.hstack([test_confounds, np.ones((test_confounds.shape[0], 1))])\n",
    "        predicted = test_confounds_aug @ betas\n",
    "        residuals = fmri_list[i] - predicted\n",
    "        residualized_runs.append(residuals)\n",
    "\n",
    "    return residualized_runs\n",
    "\n",
    "def split_runs(data, indices, spliti):\n",
    "    \"\"\"\n",
    "    Splits the data into multiple runs based on the indices and the specified dimension.\n",
    "    \n",
    "    Parameters:\n",
    "    - data: The input data to be split (can be a 4D array).\n",
    "    - indices: List of indices marking where the runs start.\n",
    "    - spliti: The axis (dimension) to split the data along. For fMRI data, spliti would typically be 3 for time.\n",
    "    \n",
    "    Returns:\n",
    "    - runs: A list containing the data split by runs.\n",
    "    \"\"\"\n",
    "    runs = []\n",
    "    for i in range(len(indices) - 1):\n",
    "        start = indices[i]\n",
    "        end = indices[i + 1]\n",
    "        \n",
    "        # Dynamically slice the data along the specified dimension (spliti)\n",
    "        # Using slicing: data[... , start:end] where `spliti` defines which axis is sliced\n",
    "        slices = [slice(None)] * data.ndim  # Create a list of slices to cover all dimensions\n",
    "        slices[spliti] = slice(start, end)  # Update the slice for the specified dimension\n",
    "        \n",
    "        run_data = data[tuple(slices)]  # Apply the slice to the data\n",
    "        runs.append(run_data)\n",
    "\n",
    "    # The last run should end at the last time point\n",
    "    start = indices[-1]\n",
    "    slices = [slice(None)] * data.ndim  # Again, create a list of slices for all dimensions\n",
    "    slices[spliti] = slice(start, None)  # Slice from the last start index to the end\n",
    "    run_data = data[tuple(slices)]\n",
    "    runs.append(run_data)\n",
    "\n",
    "    return runs\n",
    "\n",
    "def first_order_similarity(fmri):\n",
    "    L2a = []  # List to store fMRI correlations\n",
    "\n",
    "    num_timepoints = fmri.shape[0]\n",
    "\n",
    "    for t1 in range(num_timepoints):\n",
    "        for t2 in range(t1 + 1, num_timepoints):  # Upper-triangular matrix only (t2 > t1)\n",
    "            \n",
    "            # fMRI correlation: Compute correlation between voxel activity at t1 and t2\n",
    "            fmri_corr = spearmanr(fmri[t1, :], fmri[t2, :]).correlation\n",
    "            L2a.append(fmri_corr)\n",
    "\n",
    "    return L2a\n",
    "\n",
    "def mask_fmri_data(fmri_img, original_mask, roi=None):\n",
    "    if roi==\"body\" or roi==\"object\" or roi==\"scene\" or roi==\"face\":\n",
    "        mask_data = original_mask.get_fdata()\n",
    "\n",
    "        # Determine dynamic threshold (≥ 60% of subjects)\n",
    "        max_subjects_plus_1 = np.max(mask_data)\n",
    "        estimated_n_subjects = int(max_subjects_plus_1 - 1)\n",
    "        threshold = int(np.ceil(0.6 * estimated_n_subjects)) + 1  # +1 for the +1 encoding\n",
    "\n",
    "        # Create binary mask\n",
    "        binary_mask_data = (mask_data >= threshold).astype(np.uint8)\n",
    "        voxel_count = np.count_nonzero(binary_mask_data)\n",
    "\n",
    "        if voxel_count == 0:\n",
    "            raise ValueError(f\"No voxels meet the 60% threshold ({threshold}). Mask is empty.\")\n",
    "\n",
    "        # Create binary mask NIfTI\n",
    "        binary_mask_img = nib.Nifti1Image(binary_mask_data, affine=original_mask.affine, header=original_mask.header)\n",
    "\n",
    "        # Resample to fMRI image\n",
    "        mask_resampled = resample_to_img(binary_mask_img, fmri_img, interpolation=\"nearest\", force_resample=True, copy_header=True)\n",
    "\n",
    "        # Apply the mask\n",
    "        masker = NiftiMasker(mask_img=mask_resampled)\n",
    "        masked_data = masker.fit_transform(fmri_img)\n",
    "    elif roi==2:\n",
    "        mask_img = math_img(\"np.logical_or(img == 1, img == 2)\", img=original_mask)\n",
    "        mask_resampled = resample_to_img(mask_img, fmri_img, interpolation=\"nearest\", force_resample=True, copy_header=True)\n",
    "\n",
    "        # Apply mask\n",
    "        masker = NiftiMasker(mask_img=mask_resampled)\n",
    "        masked_data = masker.fit_transform(fmri_img)\n",
    "\n",
    "    else:\n",
    "        mask_img = math_img(f\"img == {roi}\", img=original_mask)\n",
    "        mask_resampled = resample_to_img(mask_img, fmri_img, interpolation=\"nearest\", force_resample=True, copy_header=True)\n",
    "\n",
    "        # Apply mask\n",
    "        masker = NiftiMasker(mask_img=mask_resampled)\n",
    "        masked_data = masker.fit_transform(fmri_img)\n",
    "\n",
    "\n",
    "    return masked_data\n",
    "\n",
    "def return_ranks_voxels(fmri_list, model_list):\n",
    "    \"\"\"\n",
    "    Rank the correlations of the voxels to the model using vectorized Spearman correlation\n",
    "    or negative absolute distance for 1D models.\n",
    "\n",
    "    Args:\n",
    "    - fmri_list: List of 5 NumPy arrays (each run's fMRI data of shape [timepoints, voxels])\n",
    "    - model_list: List of 5 NumPy arrays (each run's model time series, shape [timepoints, features] or [timepoints])\n",
    "\n",
    "    Returns:\n",
    "    - top_voxel_indices: Numpy array of the indices of the top 10% highest-ranking voxels.\n",
    "    \"\"\"\n",
    "    num_runs = len(fmri_list)\n",
    "    num_voxels = fmri_list[0].shape[1]\n",
    "    voxel_ranks = np.zeros((num_runs, num_voxels))\n",
    "\n",
    "    for i in range(num_runs):\n",
    "        train_fmri = fmri_list[i]       # Shape: (T, V)\n",
    "        train_model = model_list[i]     # Shape: (T, F) or (T,)\n",
    "\n",
    "        if train_model.ndim == 1:\n",
    "            # 1D case — use negative absolute distance\n",
    "            model_ts = rankdata(train_model) - np.mean(rankdata(train_model))  # rank and zero-mean\n",
    "            fmri_ranked = np.apply_along_axis(rankdata, 0, train_fmri) - np.mean(train_fmri, axis=0)\n",
    "\n",
    "            # Negative absolute difference per voxel\n",
    "            avg_neg_abs_dist = -np.mean(np.abs(fmri_ranked - model_ts[:, None]), axis=0)\n",
    "            voxel_ranks[i, :] = rankdata(-avg_neg_abs_dist, method='average')\n",
    "\n",
    "        else:\n",
    "            # 2D case — Spearman correlation\n",
    "            ranked_fmri = np.apply_along_axis(rankdata, 0, train_fmri)\n",
    "            ranked_model = np.apply_along_axis(rankdata, 0, train_model)\n",
    "\n",
    "            ranked_fmri -= ranked_fmri.mean(axis=0)\n",
    "            ranked_model -= ranked_model.mean(axis=0)\n",
    "\n",
    "            fmri_std = np.linalg.norm(ranked_fmri, axis=0)\n",
    "            model_std = np.linalg.norm(ranked_model, axis=0)\n",
    "\n",
    "            valid_voxels = fmri_std > 0\n",
    "            valid_features = model_std > 0\n",
    "\n",
    "            if not np.any(valid_voxels) or not np.any(valid_features):\n",
    "                print(f\"Warning: No valid voxels or model features in run {i}\")\n",
    "                voxel_ranks[i, :] = np.zeros(num_voxels)\n",
    "                continue\n",
    "\n",
    "            cov = ranked_fmri[:, valid_voxels].T @ ranked_model[:, valid_features]\n",
    "            fmri_std = fmri_std[valid_voxels]\n",
    "            model_std = model_std[valid_features]\n",
    "\n",
    "            correlation_matrix = cov / (fmri_std[:, None] * model_std[None, :])\n",
    "\n",
    "            if correlation_matrix.size == 0:\n",
    "                print(f\"Warning: Empty correlation matrix in run {i}\")\n",
    "                avg_corrs = np.zeros(valid_voxels.sum())\n",
    "            else:\n",
    "                avg_corrs = np.nanmean(correlation_matrix, axis=1)\n",
    "\n",
    "            # Create full-size average correlation vector\n",
    "            full_avg_corrs = np.full(num_voxels, -np.inf)\n",
    "            full_avg_corrs[np.where(valid_voxels)] = avg_corrs\n",
    "\n",
    "            voxel_ranks[i, :] = rankdata(-full_avg_corrs, method='average')\n",
    "\n",
    "    average_ranks = np.mean(voxel_ranks, axis=0)\n",
    "    top_voxel_count = int(0.1 * num_voxels)\n",
    "    top_voxel_indices = np.argsort(average_ranks)[:top_voxel_count]\n",
    "\n",
    "    return top_voxel_indices\n",
    "\n",
    "\n",
    "def load_and_split_trimmed(path_or_array, run_start_indices, trim_start=3, trim_end=3, is_path=True):\n",
    "    \"\"\"\n",
    "    Load a model from file or use the provided array,\n",
    "    split it into runs, and trim edges (extra 1 at start for first run).\n",
    "    \"\"\"\n",
    "    data = np.loadtxt(path_or_array, delimiter=\",\") if is_path else path_or_array\n",
    "    runs = split_runs(data, run_start_indices, 0)\n",
    "    trimmed_runs = [runs[0][trim_start + 1 : -trim_end]] + [r[trim_start:-trim_end] for r in runs[1:]]\n",
    "    return trimmed_runs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1ce1b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: /Volumes/SSD-1TB/thesis paper/data/LLM embeddings/used LLM embeddings/CLIPmultilingualmulti/CLIPmultilingualmulti_layers11-15.txt\n",
      "Loaded: CLIPmultilingualmulti_layers11-15\n",
      "Processing: /Volumes/SSD-1TB/thesis paper/data/LLM embeddings/used LLM embeddings/CLIPmultilingualtext/CLIPmultilingualtext_layers11-15.txt\n",
      "Loaded: CLIPmultilingualtext_layers11-15\n",
      "Processing: /Volumes/SSD-1TB/thesis paper/data/LLM embeddings/used LLM embeddings/XLM-roberta/XLM-roberta_layers11-15.txt\n",
      "Loaded: XLM-roberta_layers11-15\n",
      "Processing: /Volumes/SSD-1TB/thesis paper/data/LLM embeddings/used LLM embeddings/Llama/Llama_layers_layers7-11.txt\n",
      "Loaded: Llama_layers_layers7-11\n"
     ]
    }
   ],
   "source": [
    "#Loading all the foundation models and semantic models\n",
    "\n",
    "# The foundation models that are compared to the fmri data\n",
    "base_dirs = [\n",
    "    \"/Volumes/SSD-1TB/thesis paper/data/LLM embeddings/used LLM embeddings/CLIPmultilingualmulti\",\n",
    "    \"/Volumes/SSD-1TB/thesis paper/data/LLM embeddings/used LLM embeddings/CLIPmultilingualtext\",\n",
    "    \"/Volumes/SSD-1TB/thesis paper/data/LLM embeddings/used LLM embeddings/XLM-roberta\",\n",
    "    \"/Volumes/SSD-1TB/thesis paper/data/LLM embeddings/used LLM embeddings/Llama\"\n",
    "]\n",
    "\n",
    "# Dictionary to store all L1 similarity scores of the models\n",
    "models = {}\n",
    "\n",
    "# --- Process the renamed LLM model files ---\n",
    "for base_dir in base_dirs:\n",
    "    for file in os.listdir(base_dir):\n",
    "        if file.endswith(\".txt\") and (\"embedding+\" in file or \"layers\" in file):\n",
    "            file_path = os.path.join(base_dir, file)\n",
    "            print(f\"Processing: {file_path}\")\n",
    "\n",
    "            try:\n",
    "                data = load_and_split_trimmed(file_path, run_start_indices)\n",
    "                model_label = os.path.splitext(file)[0]\n",
    "                models[model_label] = data\n",
    "                print(f\"Loaded: {model_label}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {file_path}: {e}\")\n",
    "\n",
    "# semantic models\n",
    "try:\n",
    "    # models[\"editing\"] = load_and_split_trimmed(\n",
    "    #     \"/Volumes/SSD-1TB/UU - thesis/fMRI data/Full_Models/Original/editing_4pcs_conv.1D\",\n",
    "    #     run_start_indices\n",
    "    # )\n",
    "\n",
    "    # models[\"acoustic\"] = load_and_split_trimmed(\n",
    "    #     np.hstack([\n",
    "    #     np.loadtxt(\"/Volumes/SSD-1TB/UU - thesis/fMRI data/Full_Models/Original/lowlevel_soundenvelope_8pcs_conv.1D\", delimiter=\",\"),\n",
    "    #     np.loadtxt(\"/Volumes/SSD-1TB/UU - thesis/fMRI data/Full_Models/Original/lowlevel_soundpowerspectrum_5pcs_conv.1D\", delimiter=\",\")\n",
    "    #         ]), run_start_indices, is_path=False)\n",
    "    \n",
    "    # models[\"visual\"] = load_and_split_trimmed(\n",
    "    #     np.hstack([\n",
    "    #     np.loadtxt(\"/Volumes/SSD-1TB/UU - thesis/fMRI data/Full_Models/Original/lowlevel_videogist_22pcs_conv.1D\", delimiter=\",\"),\n",
    "    #     np.loadtxt(\"/Volumes/SSD-1TB/UU - thesis/fMRI data/Full_Models/Original/lowlevel_videomotion_398pcs_conv.1D\", delimiter=\",\")\n",
    "    #         ]), run_start_indices, is_path=False)\n",
    "\n",
    "    models[\"binder_abstractness\"] = load_and_split_trimmed(\n",
    "        \"/Volumes/SSD-1TB/UU - thesis/fMRI data/conv_models_1614/binder_abstractness_conv.1D\",\n",
    "        run_start_indices\n",
    "    )\n",
    "\n",
    "    models[\"binder_concreteness\"] = load_and_split_trimmed(\n",
    "        \"/Volumes/SSD-1TB/UU - thesis/fMRI data/conv_models_1614/binder_concreteness_conv.1D\",\n",
    "        run_start_indices\n",
    "    )\n",
    "\n",
    "    # models[\"word2vec\"] = load_and_split_trimmed(\n",
    "    #     \"/Volumes/SSD-1TB/UU - thesis/fMRI data/Full_Models/Original/highlevel_word2vec_72pcs_conv.1D\",\n",
    "    #     run_start_indices\n",
    "    # )\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error loading additional models: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45d525c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining all brain area masks\n",
    "\n",
    "ROIs = list(range(2, 6)) + [\"body\", \"object\", \"scene\", \"face\"]\n",
    "\n",
    "language_mask = nib.load(\"/Volumes/SSD-1TB/UU - thesis/ROIs/allParcels-language-SN220.nii\")\n",
    "scene_mask = nib.load(\"/Volumes/SSD-1TB/UU - thesis/ROIs/ventralparcels/cvs_scene_parcels/fROIs-fwhm_5-0.0001.nii\")\n",
    "body_mask = nib.load(\"/Volumes/SSD-1TB/UU - thesis/ROIs/ventralparcels/cvs_body_parcels/fROIs-fwhm_5-0.0001.nii\")\n",
    "object_mask = nib.load(\"/Volumes/SSD-1TB/UU - thesis/ROIs/ventralparcels/cvs_object_parcels/fROIs-fwhm_5-0.0001.nii\")\n",
    "face_mask = nib.load(\"/Volumes/SSD-1TB/UU - thesis/ROIs/ventralparcels/cvs_face_parcels/fROIs-fwhm_5-0.0001.nii\")\n",
    "\n",
    "# Create dictionary\n",
    "roi_masks = {\n",
    "    **{i: language_mask for i in range(2, 6)},  # ROIs 2–5 all map to language_mask (where ROI 1 and 2 are taken together)\n",
    "    \"body\": body_mask,\n",
    "    \"object\": object_mask,\n",
    "    \"scene\": scene_mask,\n",
    "    \"face\": face_mask\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf526305",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctrlAV = [12, 13, 14, 15, 16, 17, 18, 19, 22, 32]\n",
    "ctrlA = [3, 4, 5, 6, 7, 8, 9, 10, 11, 27]\n",
    "blind = [33, 35, 36, 38, 39, 41, 42, 43, 53]\n",
    "\n",
    "groups = {'blind': blind\n",
    "          ,'ctrlA': ctrlA\n",
    "          ,'ctrlAV': ctrlAV}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b12201",
   "metadata": {},
   "outputs": [],
   "source": [
    "newcorrelations = True\n",
    "storing_results = \"results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf66966",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This piece of code computes L1 scores of the foundation models and semantic models, which will be compared to the fmri data\n",
    "\n",
    "model_corr_path = storing_results + \"/model_correlations.pkl\"\n",
    "\n",
    "if os.path.exists(model_corr_path) and newcorrelations is False:\n",
    "    print(\"Loading existing model correlations\")\n",
    "    with open(model_corr_path, 'rb') as f:\n",
    "        model_correlations = pickle.load(f)\n",
    "else:\n",
    "    print(\"Computing model correlations\")\n",
    "    model_correlations = {}\n",
    "\n",
    "    for model_name, model_list in models.items():\n",
    "        per_run = []\n",
    "\n",
    "        for i in range(len(model_list)):\n",
    "            test_model = model_list[i]\n",
    "            L2b = []\n",
    "\n",
    "            num_timepoints = test_model.shape[0]\n",
    "\n",
    "            for t1 in range(num_timepoints):\n",
    "                for t2 in range(t1 + 1, num_timepoints):\n",
    "                    if test_model.ndim == 1:\n",
    "                        # 1D: Use negative absolute distance\n",
    "                        dist = -abs(test_model[t1] - test_model[t2])\n",
    "                        L2b.append(dist)\n",
    "                    else:\n",
    "                        # 2D: Use Spearman correlation\n",
    "                        corr = spearmanr(test_model[t1, :], test_model[t2, :]).correlation\n",
    "                        L2b.append(corr)\n",
    "\n",
    "            per_run.append(L2b)\n",
    "\n",
    "        model_correlations[model_name] = per_run\n",
    "\n",
    "    with open(model_corr_path, 'wb') as f:\n",
    "        pickle.dump(model_correlations, f)\n",
    "\n",
    "\n",
    "# loading the editing, sound and surprisal models\n",
    "\n",
    "acoustic_full = np.hstack([\n",
    "    np.loadtxt(\"/Volumes/SSD-1TB/UU - thesis/fMRI data/Full_Models/Original/lowlevel_soundenvelope_8pcs_conv.1D\", delimiter=\",\"),\n",
    "    np.loadtxt(\"/Volumes/SSD-1TB/UU - thesis/fMRI data/Full_Models/Original/lowlevel_soundpowerspectrum_5pcs_conv.1D\", delimiter=\",\")\n",
    "])\n",
    "\n",
    "editing = load_and_split_trimmed(\"/Volumes/SSD-1TB/UU - thesis/fMRI data/Full_Models/Original/editing_4pcs_conv.1D\", run_start_indices)\n",
    "surprisal = load_and_split_trimmed(\"/Volumes/SSD-1TB/UU - thesis/fMRI data/surprisal\", run_start_indices)\n",
    "acoustic = load_and_split_trimmed(acoustic_full, run_start_indices, is_path=False)\n",
    "\n",
    "\n",
    "#this is the actual RSA\n",
    "\n",
    "for participantgroup, ids in groups.items():\n",
    "    print(f\"Processing participant group {participantgroup}\")\n",
    "    results_dict = defaultdict(lambda: defaultdict(dict))\n",
    "    best_voxels_dict = defaultdict(lambda: defaultdict(dict))\n",
    "\n",
    "    # Fill in only `participantgroup`, keep {subj_id:03d} as a template\n",
    "    base_path_template = f\"/Volumes/SSD-1TB/UU - thesis/fMRI data/{participantgroup}/sub-{{subj_id:03d}}.nii.gz\"\n",
    "\n",
    "    for participant_id in ids:\n",
    "        print(f\"\\tProcessing participant nr.{participant_id}\")\n",
    "        fmri_path = base_path_template.format(subj_id=participant_id)\n",
    "        fmri_img = nib.load(fmri_path)\n",
    "\n",
    "        # Loop over ROIs\n",
    "        for roi, mask in roi_masks.items():\n",
    "            print(f\"\\t\\tProcessing roi {roi}\")\n",
    "\n",
    "            masked_data = mask_fmri_data(fmri_img, mask, roi)\n",
    "            fmri_list = [(runs := split_runs(masked_data, run_start_indices, 0))[0][4:-3]] + [run[3:-3] for run in runs[1:]]\n",
    "\n",
    "            for model_name, model_list in models.items():\n",
    "                if model_list[0].ndim == 1:\n",
    "                    spearman = False\n",
    "                else:\n",
    "                    spearman = True\n",
    "\n",
    "                print(f\"\\t\\t\\tProcessing model {model_name}\")\n",
    "\n",
    "                L1 = [] # Store per-participant, per roi, per model correlations\n",
    "                BV = [] # Store per participant, per roi, per model best voxels\n",
    "\n",
    "                confound_list = [np.hstack([editing[i], acoustic[i], surprisal[i]]) for i in range(len(fmri_list))]\n",
    "                residualized_fmri_list = cross_validated_residualize(fmri_list, confound_list)\n",
    "\n",
    "                #Each run becomes a test set once\n",
    "                for i in range(len(fmri_list)):\n",
    "                    print(f\"\\t\\t\\t\\tRun nr.{i} is now the testset\")\n",
    "                    \n",
    "                    # Split residualized data\n",
    "                    train_fmri = [residualized_fmri_list[j] for j in range(len(fmri_list)) if j != i]\n",
    "                    train_model = [model_list[j] for j in range(len(model_list)) if j != i]\n",
    "\n",
    "                    # Feature selection on residualized training data\n",
    "                    best_voxels = return_ranks_voxels(train_fmri, train_model)\n",
    "                    BV.append(best_voxels)\n",
    "\n",
    "                    # Apply to residualized test run\n",
    "                    test_fmri = residualized_fmri_list[i][:, best_voxels]\n",
    "\n",
    "                    # First-order similarity of residualized fMRI data\n",
    "                    fmri_corr = first_order_similarity(test_fmri)\n",
    "\n",
    "\n",
    "                    #first order similarity model --> this only needs to be done once for each model (not per participant, roi and group)\n",
    "                    model_corr = model_correlations[model_name][i] #L2b\n",
    "\n",
    "                    second_order_corr = spearmanr(fmri_corr, model_corr).correlation\n",
    "                    print(f\"\\t\\t\\t\\t\\tSecond order correlation: {second_order_corr}\")\n",
    "\n",
    "                    L1.append(second_order_corr)\n",
    "\n",
    "                L0 = np.mean(L1)\n",
    "                results_dict[participant_id][roi][model_name] = L0\n",
    "                best_voxels_dict[participant_id][roi][model_name] = BV\n",
    "\n",
    "\n",
    "    results_path = storing_results+f'/results_{participantgroup}.pkl'\n",
    "    best_voxels_path = storing_results+f'/best_voxels_{participantgroup}.pkl'\n",
    "\n",
    "    # Save results_dict\n",
    "    with open(results_path, 'wb') as f:\n",
    "        pickle.dump(dict(results_dict), f)\n",
    "\n",
    "    # Save best_voxels_dict\n",
    "    with open(best_voxels_path, 'wb') as f:\n",
    "        pickle.dump(dict(best_voxels_dict), f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d1924d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def residualize_model_data(model_data_list, surprisal_list):\n",
    "    \"\"\"\n",
    "    Residualizes each model run with respect to surprisal.\n",
    "    model_data_list: list of np arrays (1D or 2D)\n",
    "    surprisal_list: list of np arrays (1D)\n",
    "    Returns: residualized model data list\n",
    "    \"\"\"\n",
    "    residualized = []\n",
    "\n",
    "    for model_run, surprisal_run in zip(model_data_list, surprisal_list):\n",
    "        if model_run.ndim == 1:\n",
    "            X = surprisal_run.reshape(-1, 1)\n",
    "            y = model_run\n",
    "            reg = LinearRegression().fit(X, y)\n",
    "            y_pred = reg.predict(X)\n",
    "            residualized.append(y - y_pred)\n",
    "        else:\n",
    "            # 2D: residualize each feature\n",
    "            X = surprisal_run.reshape(-1, 1)\n",
    "            Y = model_run\n",
    "            Y_resid = np.zeros_like(Y)\n",
    "            for col in range(Y.shape[1]):\n",
    "                reg = LinearRegression().fit(X, Y[:, col])\n",
    "                Y_resid[:, col] = Y[:, col] - reg.predict(X)\n",
    "            residualized.append(Y_resid)\n",
    "\n",
    "    return residualized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29c2d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "acoustic_full = np.hstack([\n",
    "    np.loadtxt(\"/Volumes/SSD-1TB/UU - thesis/fMRI data/Full_Models/Original/lowlevel_soundenvelope_8pcs_conv.1D\", delimiter=\",\"),\n",
    "    np.loadtxt(\"/Volumes/SSD-1TB/UU - thesis/fMRI data/Full_Models/Original/lowlevel_soundpowerspectrum_5pcs_conv.1D\", delimiter=\",\")\n",
    "])\n",
    "\n",
    "editing = load_and_split_trimmed(\"/Volumes/SSD-1TB/UU - thesis/fMRI data/Full_Models/Original/editing_4pcs_conv.1D\", run_start_indices)\n",
    "surprisal = load_and_split_trimmed(\"/Volumes/SSD-1TB/UU - thesis/fMRI data/convolved_surprisal\", run_start_indices)\n",
    "acoustic = load_and_split_trimmed(acoustic_full, run_start_indices, is_path=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22be3631",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "model_corr_path = storing_results + \"/model_correlations.pkl\"\n",
    "\n",
    "if os.path.exists(model_corr_path) and newcorrelations is False:\n",
    "    print(\"Loading existing model correlations\")\n",
    "    with open(model_corr_path, 'rb') as f:\n",
    "        model_correlations = pickle.load(f)\n",
    "else:\n",
    "    print(\"Computing model correlations\")\n",
    "    model_correlations = {}\n",
    "\n",
    "    for model_name, model_list in models.items():\n",
    "        per_run = []\n",
    "\n",
    "        for i in range(len(model_list)):\n",
    "            test_model = model_list[i]\n",
    "            L2b = []\n",
    "\n",
    "            num_timepoints = test_model.shape[0]\n",
    "\n",
    "            for t1 in range(num_timepoints):\n",
    "                for t2 in range(t1 + 1, num_timepoints):\n",
    "                    if test_model.ndim == 1:\n",
    "                        # 1D: Use negative absolute distance\n",
    "                        dist = -abs(test_model[t1] - test_model[t2])\n",
    "                        L2b.append(dist)\n",
    "                    else:\n",
    "                        # 2D: Use Spearman correlation\n",
    "                        corr = spearmanr(test_model[t1, :], test_model[t2, :]).correlation\n",
    "                        L2b.append(corr)\n",
    "\n",
    "            per_run.append(L2b)\n",
    "\n",
    "        model_correlations[model_name] = per_run\n",
    "\n",
    "    with open(model_corr_path, 'wb') as f:\n",
    "        pickle.dump(model_correlations, f)\n",
    "\n",
    "for participantgroup, ids in groups.items():\n",
    "    print(f\"Processing participant group {participantgroup}\")\n",
    "    results_dict = defaultdict(lambda: defaultdict(dict))\n",
    "    best_voxels_dict = defaultdict(lambda: defaultdict(dict))\n",
    "\n",
    "    # Fill in only `participantgroup`, keep {subj_id:03d} as a template\n",
    "    base_path_template = f\"/Volumes/SSD-1TB/UU - thesis/fMRI data/{participantgroup}/sub-{{subj_id:03d}}.nii.gz\"\n",
    "\n",
    "    for participant_id in ids:\n",
    "        print(f\"\\tProcessing participant nr.{participant_id}\")\n",
    "        fmri_path = base_path_template.format(subj_id=participant_id)\n",
    "        fmri_img = nib.load(fmri_path)\n",
    "\n",
    "        # Loop over ROIs\n",
    "        for roi, mask in roi_masks.items():\n",
    "            print(f\"\\t\\tProcessing roi {roi}\")\n",
    "\n",
    "            masked_data = mask_fmri_data(fmri_img, mask, roi)\n",
    "            fmri_list = [(runs := split_runs(masked_data, run_start_indices, 0))[0][4:-3]] + [run[3:-3] for run in runs[1:]]\n",
    "\n",
    "            for model_name, model_list in models.items():\n",
    "                if model_list[0].ndim == 1:\n",
    "                    spearman = False\n",
    "                else:\n",
    "                    spearman = True\n",
    "\n",
    "                print(f\"\\t\\t\\tProcessing model {model_name}\")\n",
    "\n",
    "                L1 = [] # Store per-participant, per roi, per model correlations\n",
    "                BV = [] # Store per participant, per roi, per model best voxels\n",
    "\n",
    "                confound_list = [np.hstack([editing[i], acoustic[i], surprisal[i].reshape(-1, 1)]) for i in range(len(fmri_list))]\n",
    "                residualized_fmri_list = cross_validated_residualize(fmri_list, confound_list)\n",
    "\n",
    "                #Each run becomes a test set once\n",
    "                for i in range(len(fmri_list)):\n",
    "                    print(f\"\\t\\t\\t\\tRun nr.{i} is now the testset\")\n",
    "                    \n",
    "                    # Split residualized data\n",
    "                    train_fmri = [residualized_fmri_list[j] for j in range(len(fmri_list)) if j != i]\n",
    "                    train_model = [model_list[j] for j in range(len(model_list)) if j != i]\n",
    "\n",
    "                    # Feature selection on residualized training data\n",
    "                    best_voxels = return_ranks_voxels(train_fmri, train_model)\n",
    "                    BV.append(best_voxels)\n",
    "\n",
    "                    # Apply to residualized test run\n",
    "                    test_fmri = residualized_fmri_list[i][:, best_voxels]\n",
    "\n",
    "                    # First-order similarity of residualized fMRI data\n",
    "                    fmri_corr = first_order_similarity(test_fmri)\n",
    "\n",
    "\n",
    "                    #first order similarity model --> this only needs to be done once for each model (not per participant, roi and group)\n",
    "                    model_corr = model_correlations[model_name][i] #L2b\n",
    "\n",
    "                    second_order_corr = spearmanr(fmri_corr, model_corr).correlation\n",
    "                    print(f\"\\t\\t\\t\\t\\tSecond order correlation: {second_order_corr}\")\n",
    "\n",
    "                    L1.append(second_order_corr)\n",
    "\n",
    "                L0 = np.mean(L1)\n",
    "                results_dict[participant_id][roi][model_name] = L0\n",
    "                best_voxels_dict[participant_id][roi][model_name] = BV\n",
    "\n",
    "\n",
    "    results_path = storing_results+f'/results_{participantgroup}.pkl'\n",
    "    best_voxels_path = storing_results+f'/best_voxels_{participantgroup}.pkl'\n",
    "\n",
    "    # Save results_dict\n",
    "    with open(results_path, 'wb') as f:\n",
    "        pickle.dump(dict(results_dict), f)\n",
    "\n",
    "    # Save best_voxels_dict\n",
    "    with open(best_voxels_path, 'wb') as f:\n",
    "        pickle.dump(dict(best_voxels_dict), f)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
